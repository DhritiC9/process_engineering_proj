{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (only run once per environment)\n",
    "!pip install -q transformers datasets accelerate peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647356c2490a4fda8a6059df796c05e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933c6b62eea049c683105363bfa22a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac23c45914934be886081b456a67f230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81debfe70b0d431d9476f60c5ec08fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/5790r3mn7qv2tc7nkvch5yhc0000gn/T/ipykernel_82982/1829177588.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "DATA_PATH = \"/Users/dhritichandan/Downloads/Training Data Public Upload/train_data_10k.json\"\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "df = df.rename(columns={\"PFD\": \"text\", \"PID\": \"label\"})\n",
    "\n",
    "# Clean labels\n",
    "def clean_label(text):\n",
    "    return text.replace(\"(spltt)\", \"(splt)\")\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(clean_label)\n",
    "\n",
    "# Train-validation split\n",
    "train_df, val_df = train_test_split(df, test_size=0.01, random_state=42)\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "# --- Tokenizer & Model ---\n",
    "model_ckpt = \"google/byt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# --- Tokenize function with explicit return_tensors and safe label padding ---\n",
    "def tokenize_fn(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"text\"], max_length=512, padding=\"max_length\", truncation=True\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            example[\"label\"], max_length=512, padding=\"max_length\", truncation=True\n",
    "        )\n",
    "\n",
    "    # Replace padding token id's in labels with -100 to ignore them in loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Map with `remove_columns` to avoid passing unnecessary keys to the model\n",
    "tokenized_train = train_dataset.map(tokenize_fn, batched=True, remove_columns=train_dataset.column_names)\n",
    "tokenized_val = val_dataset.map(tokenize_fn, batched=True, remove_columns=val_dataset.column_names)\n",
    "\n",
    "# Set format for PyTorch tensors\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_val.set_format(\"torch\")\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_fn, batched=True, batch_size=16)\n",
    "tokenized_val = val_dataset.map(tokenize_fn, batched=True, batch_size=16)\n",
    "\n",
    "# --- Data Collator ---\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# --- Training Arguments ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./byt5-pfd-pid\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=512,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available()  # Use mixed precision if GPU available\n",
    ")\n",
    "\n",
    "# --- Trainer ---\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Empty array at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m check complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(check_dataset_for_issues(tokenized_train, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(check_dataset_for_issues(tokenized_val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m, in \u001b[0;36mcheck_dataset_for_issues\u001b[0;34m(dataset, name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sample[k]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Zero-dim tensor at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(sample[k]() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Empty array at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m check complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sample[k]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Zero-dim tensor at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(sample[k]() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Empty array at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m check complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# Check for any empty input_ids, attention_mask, or labels\n",
    "def check_dataset_for_issues(dataset, name=\"dataset\"):\n",
    "    for i, sample in enumerate(dataset):\n",
    "        if any(len(sample[k]) == 0 for k in [\"input_ids\", \"attention_mask\", \"labels\"]):\n",
    "            print(f\"❌ Zero-dim tensor at index {i} in {name}\")\n",
    "        elif any(sample[k]() == 0 for k in [\"input_ids\", \"attention_mask\", \"labels\"]):\n",
    "            print(f\"❌ Empty array at index {i} in {name}\")\n",
    "    print(f\"✅ {name} check complete\")\n",
    "\n",
    "print(check_dataset_for_issues(tokenized_train, \"train\"))\n",
    "print(check_dataset_for_issues(tokenized_val, \"val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check complete.\n",
      "None\n",
      "Check complete.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def check_dataset_for_empty_inputs(dataset):\n",
    "    for i, sample in enumerate(dataset):\n",
    "        if \"input_ids\" not in sample or \"attention_mask\" not in sample or \"labels\" not in sample:\n",
    "            print(f\"Missing keys at index {i}: {sample.keys()}\")\n",
    "        elif (len(sample[\"input_ids\"]) == 0 or\n",
    "              len(sample[\"attention_mask\"]) == 0 or\n",
    "              len(sample[\"labels\"]) == 0):\n",
    "            print(f\"Empty arrays at index {i}\")\n",
    "    print(\"Check complete.\")\n",
    "\n",
    "# Run the check\n",
    "print(check_dataset_for_empty_inputs(tokenized_train))\n",
    "print(check_dataset_for_empty_inputs(tokenized_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '(raw)(v)(tank)(pp)(v)(v)(r)<&|(raw)(v)(mix)<&|(raw)(v)&|(hex){1}(hex){2}&|[{tout}(v)(prod)]{bout}(v)(hex){3}(v)(hex){4}(rect)<1<2[{tout}(cond)(sep)[(v)(prod)](splt)[(v)(prod)](v)1]{bout}(splt)[(v)(prod)](hex){5}2n|(raw)(splt)[(hex){1}(mix)<3(prod)](v)3n|(raw)(splt)[(hex){2}(mix)<4(prod)](v)4n|(raw)(splt)[(hex){3}(mix)<5(prod)](v)5n|(raw)(v)(hex){4}(prod)n|(raw)(v)(hex){5}(prod)', 'label': '(raw)(C){FC}_1(v)<_1(mix)<&|(raw)(C){FC}_2(v)&<_2|(hex){1}(C){TC}_3(hex){2}(C){TC}_4(r)<_8<&|(raw)(v)<_5(tank)[(C){LC}_5](pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(C){FC}_7(v)&<_7|[(C){TC}_8][(C){LC}_9][{tout}(C){PC}_10(v)<_10(prod)]{bout}(v)<_9(hex){3}(C){TC}_11(C){FC}_12(v)<_12(hex){4}(C){TC}_13(rect)<1<2[(C){PC}_14][(C){LC}_15][{tout}(cond)(sep)[(C){LC}_16][(v)<_14(prod)](splt)[(v)<_16(prod)](C){FC}_17(v)1<_17]{bout}(splt)[(C){FC}_18(v)<_18(prod)](hex){5}2n|(raw)(splt)[(hex){1}(mix)<3(prod)](v)3<_3n|(raw)(splt)[(hex){2}(mix)<4(prod)](v)4<_4n|(raw)(splt)[(hex){3}(mix)<5(prod)](v)5<_11n|(raw)(v)<_13(hex){4}(prod)n|(raw)(v)<_15(hex){5}(prod)', 'input_ids': [43, 117, 100, 122, 44, 43, 121, 44, 43, 119, 100, 113, 110, 44, 43, 115, 115, 44, 43, 121, 44, 43, 121, 44, 43, 117, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 121, 44, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 121, 44, 41, 127, 43, 107, 104, 123, 44, 126, 52, 128, 43, 107, 104, 123, 44, 126, 53, 128, 41, 127, 94, 126, 119, 114, 120, 119, 128, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 126, 101, 114, 120, 119, 128, 43, 121, 44, 43, 107, 104, 123, 44, 126, 54, 128, 43, 121, 44, 43, 107, 104, 123, 44, 126, 55, 128, 43, 117, 104, 102, 119, 44, 63, 52, 63, 53, 94, 126, 119, 114, 120, 119, 128, 43, 102, 114, 113, 103, 44, 43, 118, 104, 115, 44, 94, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 43, 118, 115, 111, 119, 44, 94, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 52, 96, 126, 101, 114, 120, 119, 128, 43, 118, 115, 111, 119, 44, 94, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 43, 107, 104, 123, 44, 126, 56, 128, 53, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 52, 128, 43, 112, 108, 123, 44, 63, 54, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 54, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 53, 128, 43, 112, 108, 123, 44, 63, 55, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 55, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 54, 128, 43, 112, 108, 123, 44, 63, 56, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 56, 113, 127, 43, 117, 100, 122, 44, 43, 121, 44, 43, 107, 104, 123, 44, 126, 55, 128, 43, 115, 117, 114, 103, 44, 113, 127, 43, 117, 100, 122, 44, 43, 121, 44, 43, 107, 104, 123, 44, 126, 56, 128, 43, 115, 117, 114, 103, 44, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 70, 128, 98, 52, 43, 121, 44, 63, 98, 52, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 70, 128, 98, 53, 43, 121, 44, 41, 63, 98, 53, 127, 43, 107, 104, 123, 44, 126, 52, 128, 43, 70, 44, 126, 87, 70, 128, 98, 54, 43, 107, 104, 123, 44, 126, 53, 128, 43, 70, 44, 126, 87, 70, 128, 98, 55, 43, 117, 44, 63, 98, 59, 63, 41, 127, 43, 117, 100, 122, 44, 43, 121, 44, 63, 98, 56, 43, 119, 100, 113, 110, 44, 94, 43, 70, 44, 126, 79, 70, 128, 98, 56, 96, 43, 115, 115, 44, 94, 43, 70, 44, 126, 80, 128, 96, 43, 70, 44, 126, 83, 76, 128, 43, 70, 44, 126, 73, 70, 128, 98, 57, 43, 121, 44, 63, 98, 57, 43, 70, 44, 126, 73, 70, 128, 98, 58, 43, 121, 44, 41, 63, 98, 58, 127, 94, 43, 70, 44, 126, 87, 70, 128, 98, 59, 96, 94, 43, 70, 44, 126, 79, 70, 128, 98, 60, 96, 94, 126, 119, 114, 120, 119, 128, 43, 70, 44, 126, 83, 70, 128, 98, 52, 51, 43, 121, 44, 63, 98, 52, 51, 43, 115, 117, 114, 103, 44, 96, 126, 101, 114, 120, 119, 128, 43, 121, 44, 63, 98, 60, 43, 107, 104, 123, 44, 126, 54, 128, 43, 70, 44, 126, 87, 70, 128, 98, 52, 52, 43, 70, 44, 126, 73, 70, 128, 98, 52, 53, 43, 121, 44, 63, 98, 52, 53, 43, 107, 104, 123, 44, 126, 55, 128, 43, 70, 44, 126, 87, 70, 128, 98, 52, 54, 43, 117, 104, 102, 119, 44, 63, 52, 63, 53, 94, 43, 70, 44, 126, 83, 70, 128, 98, 52, 55, 96, 94, 43, 70, 44, 126, 79, 70, 128, 98, 52, 56, 96, 94, 126, 119, 114, 120, 119, 128, 43, 102, 114, 113, 103, 44, 43, 118, 104, 115, 44, 94, 43, 70, 44, 126, 79, 70, 128, 98, 52, 57, 96, 94, 43, 121, 44, 63, 98, 52, 55, 43, 115, 117, 114, 103, 44, 96, 43, 118, 115, 111, 119, 44, 94, 43, 121, 44, 63, 98, 52, 57, 43, 115, 117, 114, 103, 44, 96, 43, 70, 44, 126, 73, 70, 128, 98, 52, 58, 43, 121, 44, 52, 63, 98, 52, 58, 96, 126, 101, 114, 120, 119, 128, 43, 118, 115, 111, 119, 44, 94, 43, 70, 44, 126, 73, 70, 128, 98, 52, 59, 43, 121, 44, 63, 98, 52, 59, 43, 115, 117, 114, 103, 44, 96, 43, 107, 104, 123, 44, 126, 56, 128, 53, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 52, 128, 43, 112, 108, 123, 44, 63, 54, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 54, 63, 98, 54, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 1]}\n",
      "{'text': '(raw)(v)(mix)<&|(raw)(v)&|(hex){1}(mix)<&|(raw)(v)&|(hex){2}(hex){3}(mix)<3(r)(v)(splt)[(hex){3}(hex){4}(v)(hex){5}(rect)<1<2[{tout}(cond)(sep)[(v)(prod)](splt)[(v)(prod)](v)1]{bout}(splt)[(v)(prod)](hex){6}2](v)3n|(raw)(splt)[(hex){1}(mix)<4(prod)](v)4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5n|(raw)(v)(hex){6}(prod)n|(raw)(hex){4}(v)(prod)n|(raw)(v)(hex){5}(prod)', 'label': '(raw)(C){FC}_1(v)<_1(mix)<&|(raw)(C){FC}_2(v)&<_2|(hex){1}(C){TC}_3(mix)<&|(raw)(C){FC}_4(v)&<_4|(hex){2}(C){TC}_5(hex){3}(mix)<3(r)<_6[(C){TC}_6][(C){LC}_7](v)<_7(splt)[(hex){3}(hex){4}(C){TC}_8(C){FC}_9(v)<_9(hex){5}(C){TC}_10(rect)<1<2[(C){PC}_11][(C){LC}_12][{tout}(cond)(sep)[(C){LC}_13][(v)<_11(prod)](splt)[(C){FC}_14(v)<_14(prod)](v)1<_13]{bout}(splt)[(v)<_12(prod)](hex){6}2](C){FC}_15(v)3<_15n|(raw)(splt)[(hex){1}(mix)<4(prod)](v)4<_3n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_5n|(raw)(C){FC}_16(v)<_16(hex){6}(prod)n|(raw)(hex){4}(v)<_8(prod)n|(raw)(v)<_10(hex){5}(prod)', 'input_ids': [43, 117, 100, 122, 44, 43, 121, 44, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 121, 44, 41, 127, 43, 107, 104, 123, 44, 126, 52, 128, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 121, 44, 41, 127, 43, 107, 104, 123, 44, 126, 53, 128, 43, 107, 104, 123, 44, 126, 54, 128, 43, 112, 108, 123, 44, 63, 54, 43, 117, 44, 43, 121, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 54, 128, 43, 107, 104, 123, 44, 126, 55, 128, 43, 121, 44, 43, 107, 104, 123, 44, 126, 56, 128, 43, 117, 104, 102, 119, 44, 63, 52, 63, 53, 94, 126, 119, 114, 120, 119, 128, 43, 102, 114, 113, 103, 44, 43, 118, 104, 115, 44, 94, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 43, 118, 115, 111, 119, 44, 94, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 52, 96, 126, 101, 114, 120, 119, 128, 43, 118, 115, 111, 119, 44, 94, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 43, 107, 104, 123, 44, 126, 57, 128, 53, 96, 43, 121, 44, 54, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 52, 128, 43, 112, 108, 123, 44, 63, 55, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 55, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 53, 128, 43, 112, 108, 123, 44, 63, 56, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 56, 113, 127, 43, 117, 100, 122, 44, 43, 121, 44, 43, 107, 104, 123, 44, 126, 57, 128, 43, 115, 117, 114, 103, 44, 113, 127, 43, 117, 100, 122, 44, 43, 107, 104, 123, 44, 126, 55, 128, 43, 121, 44, 43, 115, 117, 114, 103, 44, 113, 127, 43, 117, 100, 122, 44, 43, 121, 44, 43, 107, 104, 123, 44, 126, 56, 128, 43, 115, 117, 114, 103, 44, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 70, 128, 98, 52, 43, 121, 44, 63, 98, 52, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 70, 128, 98, 53, 43, 121, 44, 41, 63, 98, 53, 127, 43, 107, 104, 123, 44, 126, 52, 128, 43, 70, 44, 126, 87, 70, 128, 98, 54, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 70, 128, 98, 55, 43, 121, 44, 41, 63, 98, 55, 127, 43, 107, 104, 123, 44, 126, 53, 128, 43, 70, 44, 126, 87, 70, 128, 98, 56, 43, 107, 104, 123, 44, 126, 54, 128, 43, 112, 108, 123, 44, 63, 54, 43, 117, 44, 63, 98, 57, 94, 43, 70, 44, 126, 87, 70, 128, 98, 57, 96, 94, 43, 70, 44, 126, 79, 70, 128, 98, 58, 96, 43, 121, 44, 63, 98, 58, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 54, 128, 43, 107, 104, 123, 44, 126, 55, 128, 43, 70, 44, 126, 87, 70, 128, 98, 59, 43, 70, 44, 126, 73, 70, 128, 98, 60, 43, 121, 44, 63, 98, 60, 43, 107, 104, 123, 44, 126, 56, 128, 43, 70, 44, 126, 87, 70, 128, 98, 52, 51, 43, 117, 104, 102, 119, 44, 63, 52, 63, 53, 94, 43, 70, 44, 126, 83, 70, 128, 98, 52, 52, 96, 94, 43, 70, 44, 126, 79, 70, 128, 98, 52, 53, 96, 94, 126, 119, 114, 120, 119, 128, 43, 102, 114, 113, 103, 44, 43, 118, 104, 115, 44, 94, 43, 70, 44, 126, 79, 70, 128, 98, 52, 54, 96, 94, 43, 121, 44, 63, 98, 52, 52, 43, 115, 117, 114, 103, 44, 96, 43, 118, 115, 111, 119, 44, 94, 43, 70, 44, 126, 73, 70, 128, 98, 52, 55, 43, 121, 44, 63, 98, 52, 55, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 52, 63, 98, 52, 54, 96, 126, 101, 114, 120, 119, 128, 43, 118, 115, 111, 119, 44, 94, 43, 121, 44, 63, 98, 52, 53, 43, 115, 117, 114, 103, 44, 96, 43, 107, 104, 123, 44, 126, 57, 128, 53, 96, 43, 70, 44, 126, 73, 70, 128, 98, 52, 56, 43, 121, 44, 54, 63, 98, 52, 56, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 52, 128, 43, 112, 108, 123, 44, 63, 55, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 55, 63, 98, 54, 113, 127, 43, 117, 100, 122, 44, 43, 118, 115, 111, 119, 44, 94, 43, 107, 104, 123, 44, 126, 53, 128, 43, 112, 108, 123, 44, 63, 56, 43, 115, 117, 114, 103, 44, 96, 43, 121, 44, 56, 63, 98, 56, 113, 127, 43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 70, 128, 98, 52, 57, 43, 121, 44, 63, 98, 52, 1]}\n",
      "{'text': '(raw)(hex){1}(v)(mix)<&|(raw)(v)(mix)&<&|(raw)&||(pp)(v)(r)[{bout}(v)(prod)]{tout}(v)(prod)n|(raw)(hex){1}(v)(prod)', 'label': '(raw)(hex){1}(C){TC}_1(C){FC}_2(v)<_2(mix)<&|(raw)(C){FFC}_3<_4(v)<_3(mix)&<&|(raw)(C){FT}&_4||(pp)[(C){M}](C){PI}(C){FC}_5(v)<_5(r)<_6[(C){TC}_6][(C){LC}_7][{bout}(v)<_7(prod)]{tout}(C){PC}_8(v)<_8(prod)n|(raw)(hex){1}(v)<_1(prod)', 'input_ids': [43, 117, 100, 122, 44, 43, 107, 104, 123, 44, 126, 52, 128, 43, 121, 44, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 121, 44, 43, 112, 108, 123, 44, 41, 63, 41, 127, 43, 117, 100, 122, 44, 41, 127, 127, 43, 115, 115, 44, 43, 121, 44, 43, 117, 44, 94, 126, 101, 114, 120, 119, 128, 43, 121, 44, 43, 115, 117, 114, 103, 44, 96, 126, 119, 114, 120, 119, 128, 43, 121, 44, 43, 115, 117, 114, 103, 44, 113, 127, 43, 117, 100, 122, 44, 43, 107, 104, 123, 44, 126, 52, 128, 43, 121, 44, 43, 115, 117, 114, 103, 44, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [43, 117, 100, 122, 44, 43, 107, 104, 123, 44, 126, 52, 128, 43, 70, 44, 126, 87, 70, 128, 98, 52, 43, 70, 44, 126, 73, 70, 128, 98, 53, 43, 121, 44, 63, 98, 53, 43, 112, 108, 123, 44, 63, 41, 127, 43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 73, 70, 128, 98, 54, 63, 98, 55, 43, 121, 44, 63, 98, 54, 43, 112, 108, 123, 44, 41, 63, 41, 127, 43, 117, 100, 122, 44, 43, 70, 44, 126, 73, 87, 128, 41, 98, 55, 127, 127, 43, 115, 115, 44, 94, 43, 70, 44, 126, 80, 128, 96, 43, 70, 44, 126, 83, 76, 128, 43, 70, 44, 126, 73, 70, 128, 98, 56, 43, 121, 44, 63, 98, 56, 43, 117, 44, 63, 98, 57, 94, 43, 70, 44, 126, 87, 70, 128, 98, 57, 96, 94, 43, 70, 44, 126, 79, 70, 128, 98, 58, 96, 94, 126, 101, 114, 120, 119, 128, 43, 121, 44, 63, 98, 58, 43, 115, 117, 114, 103, 44, 96, 126, 119, 114, 120, 119, 128, 43, 70, 44, 126, 83, 70, 128, 98, 59, 43, 121, 44, 63, 98, 59, 43, 115, 117, 114, 103, 44, 113, 127, 43, 117, 100, 122, 44, 43, 107, 104, 123, 44, 126, 52, 128, 43, 121, 44, 63, 98, 52, 43, 115, 117, 114, 103, 44, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train[0])\n",
    "print(tokenized_train[10])\n",
    "print(tokenized_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---- Start Training ---\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --- Evaluate ---\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions, labels, _ \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_val)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2241\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2242\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2243\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2244\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2245\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2509\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2507\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2508\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2509\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_samples(epoch_iterator, num_batches, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2511\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:5263\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5262\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5263\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(epoch_iterator))\n\u001b[1;32m   5264\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5265\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/data_loader.py:566\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/data/data_collator.py:720\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m    712\u001b[0m             batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    713\u001b[0m                 label \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label))\n\u001b[1;32m    714\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m padding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    715\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)) \u001b[38;5;241m+\u001b[39m label\n\u001b[1;32m    716\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels\n\u001b[1;32m    717\u001b[0m             ]\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m             batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 720\u001b[0m                 np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    721\u001b[0m                     [\n\u001b[1;32m    722\u001b[0m                         label,\n\u001b[1;32m    723\u001b[0m                         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m    724\u001b[0m                     ]\n\u001b[1;32m    725\u001b[0m                 )\n\u001b[1;32m    726\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m padding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    728\u001b[0m                     [\n\u001b[1;32m    729\u001b[0m                         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m    730\u001b[0m                         label,\n\u001b[1;32m    731\u001b[0m                     ]\n\u001b[1;32m    732\u001b[0m                 )\n\u001b[1;32m    733\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels\n\u001b[1;32m    734\u001b[0m             ]\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# reintroduce side effects via tokenizer that return respective datatypes for the `return_tensors` argument\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Start Training ---\n",
    "trainer.train()\n",
    "\n",
    "# --- Evaluate ---\n",
    "predictions, labels, _ = trainer.predict(tokenized_val)\n",
    "decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "# --- Sample Output ---\n",
    "print(\"\\nSample predictions vs labels:\")\n",
    "for pred, label in zip(decoded_preds[:5], decoded_labels[:5]):\n",
    "    print(f\"Prediction:\\n{pred}\\n\")\n",
    "    print(f\"Label:\\n{label}\\n\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/dhritichandan/Downloads/Training Data Public Upload/train_data_10k.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(DATA_PATH, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/dhritichandan/Downloads/Training Data Public Upload/train_data_10k.json\"\n",
    "\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "print(\"Sample data:\")\n",
    "print(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f42aea344e743e29f1126d6c3504e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after tokenization: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/5790r3mn7qv2tc7nkvch5yhc0000gn/T/ipykernel_96003/1157669707.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import torch\n",
    "\n",
    "DATA_PATH = \"/Users/dhritichandan/Downloads/Training Data Public Upload/train_data_10k.json\"\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "\n",
    "df = df.rename(columns={\"PFD\": \"text\", \"PID\": \"label\"})\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "model_ckpt = \"google/byt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
    "\n",
    "max_length = 512\n",
    "\n",
    " \n",
    "def tokenize_fn(batch):\n",
    "    inputs = tokenizer(batch[\"text\"], max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "    labels = tokenizer(batch[\"label\"], max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    new_labels = []\n",
    "    for label in labels[\"input_ids\"]:\n",
    "        new_label = [token if token != tokenizer.pad_token_id else -100 for token in label]\n",
    "        new_labels.append(new_label)\n",
    "    inputs[\"labels\"] = new_labels\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"label\"], \n",
    ")\n",
    "\n",
    "print(\"Columns after tokenization:\", tokenized_dataset.column_names)\n",
    "\n",
    "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test[\"train\"]\n",
    "eval_dataset = train_test[\"test\"]\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./byt5-pfd-pid\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_steps=200,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8000/8000 4:04:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.140744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.094095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.075844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.068132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.060561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.054156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.050760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.047932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.044923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.043966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.042142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.041485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.040621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.039662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.039292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.039318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./byt5-pfd-pid/tokenizer_config.json',\n",
       " './byt5-pfd-pid/special_tokens_map.json',\n",
       " './byt5-pfd-pid/added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./byt5-pfd-pid\")\n",
    "tokenizer.save_pretrained(\"./byt5-pfd-pid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFD Input 1:\n",
      "(raw)(hex){1}(hex){2}(mix)<2(r)[{tout}(v)(prod)]{bout}(v)(splt)[(hex){2}(hex){3}(pp)(v)(mix)<1(r)[{bout}(v)(prod)]{tout}(v)(splt)[(hex){4}(r)[{tout}(v)(prod)]{bout}(v)(hex){4}(prod)](v)1](v)2n|(raw)(hex){1}(v)(prod)n|(raw)(hex){3}(v)(prod)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=1000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=1000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction A:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(C){FC}_10(v)1<_10](hex){4}(r)<_11[(C){TC}_11][(C){LC}_12][{tout}(C){PC}_13(v)<_13(prod)]{bout}(v)<_12(hex){4}(prod)](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_5(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)[(C){TI}][(C){LC}_7][{bout}(v)<_7(prod)]{tout}(C){PC}_8(v)<_8(splt)[(hex){\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(C){FC}_10(v)1<_10](hex){4}(r)<_11[(C){TC}_11][(C){LC}_12][{tout}(C){PC}_13(v)<_13(prod)]{bout}(v)<_12(hex){4}(prod)](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_5(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)[(C){TI}][(C){LC}_2][{tout}(C){PC}_3(v)<_3(prod)]{bout}(v)<_2(splt)[(hex){2}(hex){3}(C){TC}_4(pp)[(C){M}](C){PI}(C){FC}_5(v)<_5(mix)<1(r)<_6[(C){TC}_6][(C){LC}_7][{bout}(v)<_7(prod)]{tout}(C){PC}_8(v)<_8(splt)[(hex){\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(C){FC}_10(v)1<_10](hex){4}(r)<_11[(C){TC}_11][(C){LC}_12][{tout}(C){PC}_13(v)<_13(prod)]{bout}(v)<_12(hex){4}(prod)](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_5(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)[(C){TI}][(C){LC}_2][{tout}(C){PC}_3(v)<_3(prod)]{bout}(v)<_2(splt)[(hex){2}(hex){3}(C){TC}_4(pp)[(C){M}](C){PI}(C){FC}_5(v)<_5(mix)<1(r)[(C){TI}][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){4}(r)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(C){FC}_10(v)1<_10](hex){4}(r)<_11[(C){TC}_11][(C){LC}_12][{tout}(C){PC}_13(v)<_13(prod)]{bout}(v)<_12(hex){4}(prod)](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_5(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<2(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(C){FC}_10(v)1<_10](hex){4}(r)<_11[(C){TC}_11][(C){LC}_12][{tout}(C){PC}_13(v)<_13(prod)]{bout}(v)<_12(hex){4}(prod)](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_5(prod)\n",
      "\n",
      "\n",
      "PFD Input 2:\n",
      "(raw)(v)(tank)(pp)(v)(r)<1[{bout}(v)(prod)]{tout}(v)(splt)[(hex){1}(prod)](v)(mix)1<&|(raw)(hex){2}&|n|(raw)(hex){2}(v)(prod)n|(raw)(hex){1}(v)(prod)\n",
      "\n",
      " Prediction A:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_1(prod)n|\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(v)<_1(tank)[(C){LC}_1](pp)[(C){M}<_2](C){PI}(C){FC}_2(C){FC}_3(v)<_3(r)<1<_4[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(splt)[(hex){1}(C){TC}_7(prod)](C){FC}_8(v)<_8(mix)1<&|(raw)(hex){2}(C){TC}&_9|n|(raw)(hex){2}(v)<_9(prod)n|(raw)(hex){1}(v)<_7(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_3(prod)n|\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(v)<_1(tank)[(C){LC}_1](pp)[(C){M}<_2](C){PI}(C){FC}_2(C){FC}_3(v)<_3(r)<1<_4[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(splt)[(hex){1}(C){TC}_7(prod)](C){FC}_8(v)<_8(mix)1<&|(raw)(hex){2}(C){TC}&_9|n|(raw)(hex){2}(v)<_9(prod)n|(raw)(hex){1}(v)<_7(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_5(prod)n|\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(v)<_1(tank)[(C){LC}_1](pp)[(C){M}<_2](C){PI}(C){FC}_2(C){FC}_3(v)<_3(r)<1<_4[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(splt)[(hex){1}(C){TC}_7(prod)](C){FC}_8(v)<_8(mix)1<&|(raw)(hex){2}(C){TC}&_9|n|(raw)(hex){2}(v)<_9(prod)n|(raw)(hex){1}(v)<_7(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_4(prod)n|\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(v)<_1(tank)[(C){LC}_1](pp)[(C){M}<_2](C){PI}(C){FC}_2(C){FC}_3(v)<_3(r)<1<_4[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(splt)[(hex){1}(C){TC}_7(prod)](C){FC}_8(v)<_8(mix)1<&|(raw)(hex){2}(C){TC}&_9|n|(raw)(hex){2}(v)<_9(prod)n|(raw)(hex){1}(v)<_7(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_6(prod)n|\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(v)<_1(tank)[(C){LC}_1](pp)[(C){M}<_2](C){PI}(C){FC}_2(C){FC}_3(v)<_3(r)<1<_4[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(splt)[(hex){1}(C){TC}_7(prod)](C){FC}_8(v)<_8(mix)1<&|(raw)(hex){2}(C){TC}&_9|n|(raw)(hex){2}(v)<_9(prod)n|(raw)(hex){1}(v)<_7(prod)\n",
      "\n",
      "\n",
      "PFD Input 3:\n",
      "(raw)(pp)(v)(v)(r)<&|(raw)(hex){1}(comp)&|[{tout}(v)(prod)]{bout}(v)(hex){2}(prod)n|(raw)(v)(hex){1}(prod)n|(raw)(hex){2}(v)(prod)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=1000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction A:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_8(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_8<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_8(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_5(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_8(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_3(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_8(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(pp)[(C){M}](C){PI}(C){FC}_1(v)<_1(C){FC}_2(v)<_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_8(prod)\n",
      "\n",
      "\n",
      "PFD Input 4:\n",
      "(raw)(v)(hex){1}(rect)<1<4[{tout}(cond)(sep)[(v)(prod)](splt)[(v)(hex){2}(prod)](v)1]{bout}(splt)[(v)(v)(hex){3}(rect)<2<3[{tout}(cond)(sep)[(v)(prod)](splt)[(v)(hex){4}(prod)](v)2]{bout}(splt)[(v)(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6n|(raw)(v)(hex){5}(prod)n|(raw)(v)(hex){1}(prod)n|(raw)(v)(hex){6}(prod)n|(raw)(v)(hex){3}(prod)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=1000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction A:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(C){FC}_8(v)<_8(C){FC}_9(v)<_9(hex){3}(C){TC}_10(rect)<2<3[(C){PC}_11][(C){LC\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][(C){TC}_5][{tout}(cond)(sep)[(C){LC}_6][(v)<_3(prod)](splt)[(v)<_6(hex){2}(C){TC}_7(prod)](C){FC}_8(v)1<_8]{bout}(splt)[(C){FC}_9<_5(v)<_9(C){FC}_10(v)<_10(hex){3}(C){TC}_11(rect)<2<3[(C){PC}_12][(C){LC}_13][{tout}(cond)(sep)[(C){LC}_14][(v)<_12(prod)](splt)[(C){FC}_15(v)<_15(hex){4}(C){TC}_16(prod)](v)2<_14]{bout}(splt)[(v)<_13(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_7n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_16n|(raw)(C){FC}_17(v)<_17(hex){5}(prod)n|(raw)(v)<_2(hex){1}(prod)n|(raw)(v)<_4(hex){6}(prod)n|(raw)(v)<_11(hex){3}(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(v)<_5(C){FC}_8(v)<_8(hex){3}(C){TC}_9(rect)<2<3[(C){PC}_10][(C){LC}_11][{tou\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][(C){TC}_5][{tout}(cond)(sep)[(C){LC}_6][(v)<_3(prod)](splt)[(v)<_6(hex){2}(C){TC}_7(prod)](C){FC}_8(v)1<_8]{bout}(splt)[(C){FC}_9<_5(v)<_9(C){FC}_10(v)<_10(hex){3}(C){TC}_11(rect)<2<3[(C){PC}_12][(C){LC}_13][{tout}(cond)(sep)[(C){LC}_14][(v)<_12(prod)](splt)[(C){FC}_15(v)<_15(hex){4}(C){TC}_16(prod)](v)2<_14]{bout}(splt)[(v)<_13(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_7n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_16n|(raw)(C){FC}_17(v)<_17(hex){5}(prod)n|(raw)(v)<_2(hex){1}(prod)n|(raw)(v)<_4(hex){6}(prod)n|(raw)(v)<_11(hex){3}(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(C){FC}_6(v)<_6(hex){2}(C){TC}_7(prod)](v)1<_5]{bout}(splt)[(v)<_5(C){FC}_8(v)<_8(hex){3}(C){TC}_9(rect)<2<3[(C){PC}_10][(C){LC}_11][{tou\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][(C){TC}_5][{tout}(cond)(sep)[(C){LC}_6][(v)<_3(prod)](splt)[(v)<_6(hex){2}(C){TC}_7(prod)](C){FC}_8(v)1<_8]{bout}(splt)[(C){FC}_9<_5(v)<_9(C){FC}_10(v)<_10(hex){3}(C){TC}_11(rect)<2<3[(C){PC}_12][(C){LC}_13][{tout}(cond)(sep)[(C){LC}_14][(v)<_12(prod)](splt)[(C){FC}_15(v)<_15(hex){4}(C){TC}_16(prod)](v)2<_14]{bout}(splt)[(v)<_13(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_7n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_16n|(raw)(C){FC}_17(v)<_17(hex){5}(prod)n|(raw)(v)<_2(hex){1}(prod)n|(raw)(v)<_4(hex){6}(prod)n|(raw)(v)<_11(hex){3}(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(v)<_6(C){FC}_8(v)<_8(hex){3}(C){TC}_9(rect)<2<3[(C){PC}_10][(C){LC}_11][{tou\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][(C){TC}_5][{tout}(cond)(sep)[(C){LC}_6][(v)<_3(prod)](splt)[(v)<_6(hex){2}(C){TC}_7(prod)](C){FC}_8(v)1<_8]{bout}(splt)[(C){FC}_9<_5(v)<_9(C){FC}_10(v)<_10(hex){3}(C){TC}_11(rect)<2<3[(C){PC}_12][(C){LC}_13][{tout}(cond)(sep)[(C){LC}_14][(v)<_12(prod)](splt)[(C){FC}_15(v)<_15(hex){4}(C){TC}_16(prod)](v)2<_14]{bout}(splt)[(v)<_13(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_7n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_16n|(raw)(C){FC}_17(v)<_17(hex){5}(prod)n|(raw)(v)<_2(hex){1}(prod)n|(raw)(v)<_4(hex){6}(prod)n|(raw)(v)<_11(hex){3}(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(C){FC}_6(v)<_6(hex){2}(C){TC}_7(prod)](v)1<_4]{bout}(splt)[(v)<_5(C){FC}_8(v)<_8(hex){3}(C){TC}_9(rect)<2<3[(C){PC}_10][(C){LC}_11][{tou\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][(C){TC}_5][{tout}(cond)(sep)[(C){LC}_6][(v)<_3(prod)](splt)[(v)<_6(hex){2}(C){TC}_7(prod)](C){FC}_8(v)1<_8]{bout}(splt)[(C){FC}_9<_5(v)<_9(C){FC}_10(v)<_10(hex){3}(C){TC}_11(rect)<2<3[(C){PC}_12][(C){LC}_13][{tout}(cond)(sep)[(C){LC}_14][(v)<_12(prod)](splt)[(C){FC}_15(v)<_15(hex){4}(C){TC}_16(prod)](v)2<_14]{bout}(splt)[(v)<_13(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_7n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_16n|(raw)(C){FC}_17(v)<_17(hex){5}(prod)n|(raw)(v)<_2(hex){1}(prod)n|(raw)(v)<_4(hex){6}(prod)n|(raw)(v)<_11(hex){3}(prod)\n",
      "\n",
      "\n",
      "PFD Input 5:\n",
      "(raw)(comp)(v)(r)<&|(raw)(hex)&|[{bout}(v)(prod)]{tout}(v)(pp)(v)(prod)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=1000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction A:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(comp)[(C){M}<_3](C){PC}_3(C){FC}_4(v)&<_4|[(C){TI}][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(pp)[(C){M}](C){PI}(C){FC}_7(v)<_7(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<_5<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<_5<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(pp)[(C){M}](C){PI}(C){FC}_7(v)<_7(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<_5<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)](C){FC}_7(v)<_7(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Text2TextGenerationPipeline\n",
    "\n",
    "pipeline = Text2TextGenerationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1  \n",
    ")\n",
    "\n",
    "sample_inputs = [df[\"text\"].iloc[i] for i in range(5)]  \n",
    "max_new_tokens=1000\n",
    "for i, input_text in enumerate(sample_inputs):\n",
    "    print(f\"\\nPFD Input {i+1}:\\n{input_text}\\n\")\n",
    "    \n",
    "    outputs = pipeline(\n",
    "        input_text,\n",
    "        max_length=max_new_tokens,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    for j, output in enumerate(outputs):\n",
    "        print(f\" Prediction {chr(65+j)}:\\n{output['generated_text']}\\n\")\n",
    "        print(f\" Ground Truth PID:\\n{df['label'].iloc[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2f0ff3862946e69c2307207b44ed68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after tokenization: ['input_ids', 'attention_mask', 'labels']\n",
      "\n",
      " PFD Input 1:\n",
      "(raw)(hex){1}(hex){2}(mix)<2(r)[{tout}(v)(prod)]{bout}(v)(splt)[(hex){2}(hex){3}(pp)(v)(mix)<1(r)[{bout}(v)(prod)]{tout}(v)(splt)[(hex){4}(r)[{tout}(v)(prod)]{bout}(v)(hex){4}(prod)](v)1](v)2n|(raw)(hex){1}(v)(prod)n|(raw)(hex){3}(v)(prod)\n",
      "\n",
      " Prediction A:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(hex){4}(r)<_10[(C){TC}_10][(C){LC}_11][{tout}(C){PC}_12(v)<_12(prod)]{bout}(v)<_10(hex){4}(prod)](C){FC}_13(v)1<_13](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_14(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(hex){4}(r)<_10[(C){TC}_10][(C){LC}_11][{tout}(C){PC}_12(v)<_12(prod)]{bout}(v)<_11(hex){4}(prod)](C){FC}_13(v)1<_13](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_14(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(hex){4}(r)<_10[(C){TC}_10][(C){LC}_11][{tout}(C){PC}_12(v)<_12(prod)]{bout}(v)<_10(hex){4}(prod)](C){FC}_13(v)1<_13](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_9(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(hex){4}(r)<_10[(C){TC}_10][(C){LC}_11][{tout}(C){PC}_12(v)<_12(prod)]{bout}(v)<_11(hex){4}(prod)](C){FC}_13(v)1<_13](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_9(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(hex){4}(r)<_10[(C){TC}_10][(C){LC}_11][{tout}(C){PC}_12(v)<_12(prod)]{bout}(v)<_10(hex){4}(prod)](C){FC}_13(v)1<_13](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_11(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(hex){2}(mix)<2(r)<_2[(C){TC}_2][(C){LC}_3][{tout}(C){PC}_4(v)<_4(prod)]{bout}(v)<_3(splt)[(hex){2}(hex){3}(C){TC}_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8][{bout}(v)<_8(prod)]{tout}(C){PC}_9(v)<_9(splt)[(C){FC}_10(v)1<_10](hex){4}(r)<_11[(C){TC}_11][(C){LC}_12][{tout}(C){PC}_13(v)<_13(prod)]{bout}(v)<_12(hex){4}(prod)](C){FC}_14(v)2<_14n|(raw)(hex){1}(v)<_1(prod)n|(raw)(hex){3}(v)<_5(prod)\n",
      "============================================================\n",
      "\n",
      " PFD Input 2:\n",
      "(raw)(v)(tank)(pp)(v)(r)<1[{bout}(v)(prod)]{tout}(v)(splt)[(hex){1}(prod)](v)(mix)1<&|(raw)(hex){2}&|n|(raw)(hex){2}(v)(prod)n|(raw)(hex){1}(v)(prod)\n",
      "\n",
      " Prediction A:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_1(prod)n|(raw)(hex){1}(v)<_1(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_3(prod)n|(raw)(hex){1}(v)<_1(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_5(prod)n|(raw)(hex){1}(v)<_1(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_4(prod)n|(raw)(hex){1}(v)<_1(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(hex){1}(C){TC}_1(mix)<1(r)<_1<&|(raw)(v)<_2(tank)[(C){LC}_2](pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{bout}(v)<_6(prod)]{tout}(C){PC}_7(v)<_7(splt)[(hex){2}(C){TC}_8(prod)](C){FC}_9(v)1<_9n|(raw)(hex){2}(v)<_6(prod)n|(raw)(hex){1}(v)<_1(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(v)<_1(tank)[(C){LC}_1](pp)[(C){M}<_2](C){PI}(C){FC}_2(C){FC}_3(v)<_3(r)<1<_4[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(splt)[(hex){1}(C){TC}_7(prod)](C){FC}_8(v)<_8(mix)1<&|(raw)(hex){2}(C){TC}&_9|n|(raw)(hex){2}(v)<_9(prod)n|(raw)(hex){1}(v)<_7(prod)\n",
      "============================================================\n",
      "\n",
      " PFD Input 3:\n",
      "(raw)(pp)(v)(v)(r)<&|(raw)(hex){1}(comp)&|[{tout}(v)(prod)]{bout}(v)(hex){2}(prod)n|(raw)(v)(hex){1}(prod)n|(raw)(hex){2}(v)(prod)\n",
      "\n",
      " Prediction A:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_10(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_8<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_10(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_5(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_10(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_3(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_10(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(hex){1}(C){TC}_1(comp)[(C){M}<_2](C){PC}_2(r)<_5<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)&<_4|[(C){TC}_5][(C){LC}_6][{tout}(C){PC}_7(v)<_7(prod)]{bout}(v)<_6(hex){2}(C){TC}_8(prod)n|(raw)(C){FC}_9<_1(v)<_9(hex){1}(prod)n|(raw)(hex){2}(v)<_8(prod)\n",
      "============================================================\n",
      "\n",
      " PFD Input 4:\n",
      "(raw)(v)(hex){1}(rect)<1<4[{tout}(cond)(sep)[(v)(prod)](splt)[(v)(hex){2}(prod)](v)1]{bout}(splt)[(v)(v)(hex){3}(rect)<2<3[{tout}(cond)(sep)[(v)(prod)](splt)[(v)(hex){4}(prod)](v)2]{bout}(splt)[(v)(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6n|(raw)(v)(hex){5}(prod)n|(raw)(v)(hex){1}(prod)n|(raw)(v)(hex){6}(prod)n|(raw)(v)(hex){3}(prod)\n",
      "\n",
      " Prediction A:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(C){FC}_8(v)<_8(C){FC}_9(v)<_9(hex){3}(C){TC}_10(rect)<2<3[(C){PC}_11][(C){LC}_12][{tout}(cond)(sep)[(C){LC}_13][(v)<_11(prod)](splt)[(v)<_13(hex){4}(C){TC}_14(prod)](C){FC}_15(v)2<_15]{bout}(splt)[(v)<_11(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_5n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_1n|(raw)(C){FC}_16(v)<_16(hex){5}(prod)n|(raw)(C){FC}_17(v)<_17(hex){6}(prod)n|(raw)(v)<_8(hex){3}(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(C){FC}_8(v)<_8(C){FC}_9(v)<_9(hex){3}(C){TC}_10(rect)<2<3[(C){PC}_11][(C){LC}_12][{tout}(cond)(sep)[(C){LC}_13][(v)<_11(prod)](splt)[(v)<_13(hex){4}(C){TC}_14(prod)](C){FC}_15(v)2<_15]{bout}(splt)[(v)<_11(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_5n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_1n|(raw)(C){FC}_16(v)<_16(hex){5}(prod)n|(raw)(C){FC}_17(v)<_17(hex){6}(prod)n|(raw)(v)<_9(hex){3}(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(C){FC}_8(v)<_8(C){FC}_9(v)<_9(hex){3}(C){TC}_10(rect)<2<3[(C){PC}_11][(C){LC}_12][{tout}(cond)(sep)[(C){LC}_13][(v)<_11(prod)](splt)[(v)<_13(hex){4}(C){TC}_14(prod)](C){FC}_15(v)2<_15]{bout}(splt)[(v)<_11(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_5n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_1n|(raw)(C){FC}_16(v)<_16(hex){5}(prod)n|(raw)(C){FC}_17(v)<_17(hex){6}(prod)n|(raw)(v)<_7(hex){3}(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(C){FC}_8(v)<_8(C){FC}_9(v)<_9(hex){3}(C){TC}_10(rect)<2<3[(C){PC}_11][(C){LC}_12][{tout}(cond)(sep)[(C){LC}_13][(v)<_11(prod)](splt)[(v)<_13(hex){4}(C){TC}_14(prod)](C){FC}_15(v)2<_15]{bout}(splt)[(v)<_11(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_5n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_1n|(raw)(C){FC}_16(v)<_16(hex){5}(prod)n|(raw)(C){FC}_17(v)<_17(hex){6}(prod)n|(raw)(v)<_15(hex){3}(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][{tout}(cond)(sep)[(C){LC}_5][(v)<_3(prod)](splt)[(v)<_5(hex){2}(C){TC}_6(prod)](C){FC}_7(v)1<_7]{bout}(splt)[(C){FC}_8(v)<_8(C){FC}_9(v)<_9(hex){3}(C){TC}_10(rect)<2<3[(C){PC}_11][(C){LC}_12][{tout}(cond)(sep)[(C){LC}_13][(v)<_11(prod)](splt)[(v)<_13(hex){4}(C){TC}_14(prod)](C){FC}_15(v)2<_15]{bout}(splt)[(v)<_11(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_1n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_1n|(raw)(C){FC}_16(v)<_16(hex){5}(prod)n|(raw)(C){FC}_17(v)<_17(hex){6}(prod)n|(raw)(v)<_15(hex){3}(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(C){FC}_1(v)<_1(hex){1}(C){TC}_2(rect)<1<4[(C){PC}_3][(C){LC}_4][(C){TC}_5][{tout}(cond)(sep)[(C){LC}_6][(v)<_3(prod)](splt)[(v)<_6(hex){2}(C){TC}_7(prod)](C){FC}_8(v)1<_8]{bout}(splt)[(C){FC}_9<_5(v)<_9(C){FC}_10(v)<_10(hex){3}(C){TC}_11(rect)<2<3[(C){PC}_12][(C){LC}_13][{tout}(cond)(sep)[(C){LC}_14][(v)<_12(prod)](splt)[(C){FC}_15(v)<_15(hex){4}(C){TC}_16(prod)](v)2<_14]{bout}(splt)[(v)<_13(prod)](hex){5}3](hex){6}4n|(raw)(splt)[(hex){2}(mix)<5(prod)](v)5<_7n|(raw)(splt)[(hex){4}(mix)<6(prod)](v)6<_16n|(raw)(C){FC}_17(v)<_17(hex){5}(prod)n|(raw)(v)<_2(hex){1}(prod)n|(raw)(v)<_4(hex){6}(prod)n|(raw)(v)<_11(hex){3}(prod)\n",
      "============================================================\n",
      "\n",
      " PFD Input 5:\n",
      "(raw)(comp)(v)(r)<&|(raw)(hex)&|[{bout}(v)(prod)]{tout}(v)(pp)(v)(prod)\n",
      "\n",
      " Prediction A:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(comp)[(C){M}<_3](C){PC}_3(C){FC}_4(v)&<_4|[(C){TI}][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(pp)[(C){M}](C){PI}(C){FC}_7(v)<_7(prod)\n",
      "\n",
      " Prediction B:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<_5<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Prediction C:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<_5<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TC}_4][(C){LC}_5][{bout}(v)<_5(prod)]{tout}(C){PC}_6(v)<_6(pp)[(C){M}](C){PI}(C){FC}_7(v)<_7(prod)\n",
      "\n",
      " Prediction D:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n",
      " Prediction E:\n",
      "(raw)(hex)<_1(C){TC}_1(r)<_5<&|(raw)(comp)[(C){M}<_2](C){PC}_2(C){FC}_3(v)&<_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)](C){FC}_7(v)<_7(prod)\n",
      "\n",
      " Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Text2TextGenerationPipeline\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "DATA_PATH = \"/Users/dhritichandan/Downloads/Training Data Public Upload/train_data_10k.json\"\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "\n",
    "df = df.rename(columns={\"PFD\": \"text\", \"PID\": \"label\"})\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "model_ckpt = \"google/byt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
    "\n",
    "max_length = 512\n",
    "\n",
    " \n",
    "def tokenize_fn(batch):\n",
    "    inputs = tokenizer(batch[\"text\"], max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "    labels = tokenizer(batch[\"label\"], max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    new_labels = []\n",
    "    for label in labels[\"input_ids\"]:\n",
    "        new_label = [token if token != tokenizer.pad_token_id else -100 for token in label]\n",
    "        new_labels.append(new_label)\n",
    "    inputs[\"labels\"] = new_labels\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"label\"], \n",
    ")\n",
    "\n",
    "print(\"Columns after tokenization:\", tokenized_dataset.column_names)\n",
    "\n",
    "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test[\"train\"]\n",
    "eval_dataset = train_test[\"test\"]\n",
    "\n",
    "\n",
    "\n",
    "model_dir = \"./byt5-pfd-pid\" \n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "pipeline = Text2TextGenerationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "sample_inputs = [df[\"text\"].iloc[i] for i in range(5)]  \n",
    "\n",
    "\n",
    "for i, input_text in enumerate(sample_inputs):\n",
    "    print(f\"\\n PFD Input {i+1}:\\n{input_text}\\n\")\n",
    "\n",
    "    outputs = pipeline(\n",
    "        input_text,\n",
    "        max_new_tokens=1000,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    for j, output in enumerate(outputs):\n",
    "        print(f\" Prediction {chr(65+j)}:\\n{output['generated_text']}\\n\")\n",
    "\n",
    "    print(f\" Ground Truth PID:\\n{df['label'].iloc[i]}\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFD Input:\n",
      "(raw)(pp)(v)(v)(mix)<&|(raw)(hex)(v)&|(mix)<&|(raw)(v)&|(pp)(v)(mix)<1(r)(v)(splt)[(prod)](v)1\n",
      "\n",
      "Prediction A:\n",
      "(raw)(hex)<_1(C){TC}_1(C){FC}_2(v)<_2(mix)<&|(raw)(hex)<_3(C){TC}_3(C){FC}_4(v)&<_4|(mix)<&|(raw)(C){FC}_5(v)&<_5|(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8](v)<_8(splt)[(prod)](C){FC}_9(v)1<_9\n",
      "\n",
      "Prediction B:\n",
      "(raw)(hex)<_1(C){TC}_1(C){FC}_2(v)<_2(mix)<&|(raw)(C){FC}_3(v)&<_3|(mix)<&|(raw)(C){FC}_4(v)&<_4|(pp)[(C){M}](C){PI}(C){FC}_5(v)<_5(mix)<1(r)<_6[(C){TC}_6][(C){LC}_7](v)<_7(splt)[(prod)](C){FC}_8(v)1<_8\n",
      "\n",
      "Prediction C:\n",
      "(raw)(hex)<_1(C){TC}_1(C){FC}_2(v)<_2(mix)<&|(raw)(pp)[(C){M}](C){PI}(C){FC}_3(v)<_3(C){FC}_4(v)<_4(mix)<&|(raw)(C){FC}_5(v)&<_5|(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8](v)<_8(splt)[(prod)](C){FC}_9(v)1<_9\n",
      "\n",
      "Prediction D:\n",
      "(raw)(hex)<_1(C){TC}_1(C){FC}_2(v)<_2(mix)<&|(raw)(hex)<_3(C){TC}_3(C){FC}_4(v)&<_4|(mix)<&|(raw)(C){FC}_5(v)&<_5|(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(mix)<1(r)<_7[(C){TC}_7][(C){LC}_8](v)<_8(splt)[(prod)](C){FC}_9(v)1<_9\n",
      "\n",
      "\n",
      "Prediction E:\n",
      "(raw)(hex)<_1(C){TC}_1(C){FC}_2(v)<_2(mix)<&|(raw)(C){FC}_3(v)&<_3|(mix)<&|(raw)(C){FC}_4(v)&<_4|(pp)[(C){M}](C){PI}(C){FC}_5(v)<_5(mix)<1(r)<_6[(C){TC}_6][(C){LC}_7](v)<_7(splt)[(prod)](C){FC}_8(v)1<_8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_input = \"(raw)(pp)(v)(v)(mix)<&|(raw)(hex)(v)&|(mix)<&|(raw)(v)&|(pp)(v)(mix)<1(r)(v)(splt)[(prod)](v)1\"\n",
    "\n",
    "print(f\"\\nPFD Input:\\n{sample_input}\\n\")\n",
    "\n",
    "outputs = pipeline(\n",
    "    sample_input,\n",
    "    max_new_tokens=700,     # use max_new_tokens, not max_length\n",
    "    num_beams=5,\n",
    "    num_return_sequences=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "for j, output in enumerate(outputs):\n",
    "    print(f\"Prediction {chr(65+j)}:\\n{output['generated_text']}\\n\")\n",
    "    # If you want to print ground truth for that input, you can do so here:\n",
    "    # print(f\"Ground Truth PID:\\n{df['label'].iloc[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ground Truth PID:\n",
      "(raw)(comp)[(C){M}<_1](C){PC}_1(C){FC}_2(v)<_2(r)<&|(raw)(hex)<_3(C){TC}&_3|[(C){TI}][(C){LC}_4][{bout}(v)<_4(prod)]{tout}(C){PC}_5(v)<_5(pp)[(C){M}](C){PI}(C){FC}_6(v)<_6(prod)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "input_ids length: 512\n",
      "labels length: 512\n",
      "input_ids type: <class 'list'>\n",
      "labels type: <class 'list'>\n",
      "Sample 1\n",
      "input_ids length: 512\n",
      "labels length: 512\n",
      "input_ids type: <class 'list'>\n",
      "labels type: <class 'list'>\n",
      "Sample 2\n",
      "input_ids length: 512\n",
      "labels length: 512\n",
      "input_ids type: <class 'list'>\n",
      "labels type: <class 'list'>\n",
      "Sample 3\n",
      "input_ids length: 512\n",
      "labels length: 512\n",
      "input_ids type: <class 'list'>\n",
      "labels type: <class 'list'>\n",
      "Sample 4\n",
      "input_ids length: 512\n",
      "labels length: 512\n",
      "input_ids type: <class 'list'>\n",
      "labels type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Sample {i}\")\n",
    "    print(\"input_ids length:\", len(tokenized_train[i]['input_ids']))\n",
    "    print(\"labels length:\", len(tokenized_train[i]['labels']))\n",
    "    print(\"input_ids type:\", type(tokenized_train[i]['input_ids']))\n",
    "    print(\"labels type:\", type(tokenized_train[i]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/5790r3mn7qv2tc7nkvch5yhc0000gn/T/ipykernel_82982/2342620712.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m small_val \u001b[38;5;241m=\u001b[39m tokenized_val\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      6\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mcollator\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2241\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2242\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2243\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2244\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2245\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2509\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2507\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2508\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2509\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_samples(epoch_iterator, num_batches, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2511\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:5263\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5262\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5263\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(epoch_iterator))\n\u001b[1;32m   5264\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5265\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/data_loader.py:566\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/data/data_collator.py:720\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m    712\u001b[0m             batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    713\u001b[0m                 label \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label))\n\u001b[1;32m    714\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m padding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    715\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)) \u001b[38;5;241m+\u001b[39m label\n\u001b[1;32m    716\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels\n\u001b[1;32m    717\u001b[0m             ]\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m             batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 720\u001b[0m                 np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    721\u001b[0m                     [\n\u001b[1;32m    722\u001b[0m                         label,\n\u001b[1;32m    723\u001b[0m                         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m    724\u001b[0m                     ]\n\u001b[1;32m    725\u001b[0m                 )\n\u001b[1;32m    726\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m padding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    728\u001b[0m                     [\n\u001b[1;32m    729\u001b[0m                         np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_pad_token_id] \u001b[38;5;241m*\u001b[39m (max_label_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m    730\u001b[0m                         label,\n\u001b[1;32m    731\u001b[0m                     ]\n\u001b[1;32m    732\u001b[0m                 )\n\u001b[1;32m    733\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels\n\u001b[1;32m    734\u001b[0m             ]\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# reintroduce side effects via tokenizer that return respective datatypes for the `return_tensors` argument\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "small_train = tokenized_train.select(range(10))\n",
    "small_val = tokenized_val.select(range(5))\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train,\n",
    "    eval_dataset=small_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
